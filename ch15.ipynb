{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": ["import pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.metrics import pairwise\nfrom scipy.cluster.hierarchy import dendrogram, linkage, fcluster\nfrom sklearn.cluster import KMeans\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom pandas.plotting import parallel_coordinates\n\nutilities_df = pd.read_csv('Utilities.csv')\n# set row names to the utilities column\nutilities_df.set_index('Company', inplace=True)\n# while not required, the conversion of integer data to float\n# will avoid a warning when applying the scale function\nutilities_df = utilities_df.apply(lambda x: x.astype('float64'))\n# compute Euclidean distance\nd = pairwise.pairwise_distances(utilities_df,\nmetric='euclidean')\npd.DataFrame(d, columns=utilities_df.index,\nindex=utilities_df.index)\n\n# code for normalizing data and computing distance\n# scikit-learn uses population standard deviation\nutilities_df_norm = utilities_df.apply(preprocessing.scale,\naxis=0)\n# pandas uses sample standard deviation\nutilities_df_norm = (utilities_df - utilities_df.mean())/utilities_df.std()\n# compute normalized distance based on Sales and Fuel Cost\nutilities_df_norm[['Sales', 'Fuel_Cost']]\nd_norm = pairwise.pairwise_distances(utilities_df_norm[['Sales', 'Fuel_Cost']], metric='euclidean')\npd.DataFrame(d_norm, columns=utilities_df.index, index=utilities_df.index)\n\n# code for running hierarchical clustering and generating a dendrogram\n# in linkage() set argument method =\n# 'single', 'complete', 'average', 'weighted', centroid', 'median', 'ward'\nZ = linkage(utilities_df_norm, method='single')\ndendrogram(Z, labels=utilities_df_norm.index,\ncolor_threshold=2.75)\nZ = linkage(utilities_df_norm, method='average')\ndendrogram(Z, labels=utilities_df_norm.index,\ncolor_threshold=3.6)\n\n\n# Single Linkage (output modified for clarity)\nmemb = fcluster(linkage(utilities_df_norm, method='single'), 6, criterion='maxclust')\nmemb = pd.Series(memb, index=utilities_df_norm.index)\n\n# Average Linkage (output modified for clarity)\nmemb = fcluster(linkage(utilities_df_norm,method='average'), 6, criterion='maxclust')\nmemb = pd.Series(memb, index=utilities_df_norm.index)\n\n\n# code for creating heatmap\n# set labels as cluster membership and utility name\nutilities_df_norm.index = ['{}: {}'.format(cluster, state) for cluster, state in zip(memb,utilities_df_norm.index)]\n# plot heatmap\n# the '_r' suffix reverses the color mapping to large = dark\nsns.clustermap(utilities_df_norm, method='average',\ncol_cluster=False, cmap='mako_r')\n\n\n\n\n# code for k-means\n# Load and preprocess data\nutilities_df = pd.read_csv('Utilities.csv')\nutilities_df.set_index('Company', inplace=True)\nutilities_df = utilities_df.apply(lambda x:\nx.astype('float64'))\n# Normalize distances\nutilities_df_norm = utilities_df.apply(preprocessing.scale,\naxis=0)\nkmeans = KMeans(n_clusters=6,\nrandom_state=0).fit(utilities_df_norm)\n# Cluster membership\nmemb = pd.Series(kmeans.labels_, index=utilities_df_norm.index)\nfor key, item in memb.groupby(memb):\n  print(key, ': ', ', '.join(item.index))\n\n# Within-cluster sum of squared distances and cluster count\n# calculate the distances of each data point to the cluster centers\ndistances = kmeans.transform(utilities_df_norm)\n# find closest cluster for each data point\nminSquaredDistances = distances.min(axis=1) ** 2\n# combine with cluster labels into a data frame\ndf = pd.DataFrame({'squaredDistance': minSquaredDistances, 'cluster': kmeans.labels_}, index=utilities_df_norm.index)\n# group by cluster and print information\nfor cluster, data in df.groupby('cluster'):\n  count = len(data)\n  withinClustSS = data.squaredDistance.sum()\n  print(f'Cluster cluster (count members):  withinClustSS:.2f within cluster ')\n\n  \ncentroids = pd.DataFrame(kmeans.cluster_centers_, columns=utilities_df_norm.columns)\npd.set_option('precision', 3)\n# calculate the distances of each data point to the cluster centers\ndistances = kmeans.transform(utilities_df_norm)\n# find closest cluster for each data point\nminSquaredDistances = distances.min(axis=1) ** 2\n# combine with cluster labels into a data frame\ndf = pd.DataFrame({'squaredDistance': minSquaredDistances, 'cluster': kmeans.labels_}, index=utilities_df_norm.index)\n# group by cluster and print information\nfor cluster, data in df.groupby('cluster'):\n  count = len(data)\n  withinClustSS = data.squaredDistance.sum()\n  print(f'Cluster cluster (count members):withinClustSS:.2f within cluster ')\n  \n  \n  \n# code for plotting profile plot of centroids\ncentroids['cluster'] = ['Cluster '.format(i) for i in centroids.index]\nplt.figure(figsize=(10,6))\nparallel_coordinates(centroids, class_column='cluster',\ncolormap='Dark2', linewidth=5)\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n\n## code for preparing Figure 15.6\ninertia = []\nfor n_clusters in range(1, 7):\n  kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(utilities_df_norm)\n  inertia.append(kmeans.inertia_ / n_clusters)\ninertias = pd.DataFrame({'n_clusters': range(1, 7), 'inertia': inertia})\nax = inertias.plot(x='n_clusters', y='inertia')\nplt.xlabel('Number of clusters (k)')\nplt.ylabel('Average Within-Cluster Squared Distances')\nplt.ylim((0, 1.1 * inertias.inertia.max()))\nax.legend().set_visible(False)\nplt.show()\n\n"]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}